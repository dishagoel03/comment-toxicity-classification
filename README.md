# comment-toxicity-classification
The Comment Toxicity Classification Model is a machine learning project focused on classifying the toxicity levels of comments using state-of-the-art Natural Language Processing (NLP) techniques. It serves as a powerful tool to categorize comments into different toxicity levels, from non-toxic to highly toxic. The objective is to contribute to a healthier online communication environment by enabling real-time assessment and moderation of comments. This project utilizes Python, TensorFlow, Keras, Pandas, and Matplotlib to efficiently process and classify textual data, ultimately promoting a more respectful and engaging online discourse.

# About Dataset
The [dataset](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data) used in this project is available on Kaggle platform. The dataset contains a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:
- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate





